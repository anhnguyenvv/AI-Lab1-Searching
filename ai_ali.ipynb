{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhnguyenvv/AI-Lab1-Searching/blob/main/ai_ali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjLr_-jz7r9W",
        "outputId": "b601a25d-3d60-4c4b-f8b6-fc6e828237d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,858 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,084 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,129 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [47.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,377 kB]\n",
            "Fetched 6,907 kB in 2s (4,108 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio -q\n",
        "!pip install openai -q\n",
        "!pip install gtts -q\n",
        "!pip install pydub -q\n",
        "!pip install config -q\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install gdown -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gTENxSh492It"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import config\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "import requests, gdown\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNtL67nSBNSq"
      },
      "source": [
        "### load whisper model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAlxhz_lFejg",
        "outputId": "de6a5a10-c4d7-47b9-fdf3-68a6d06c0e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:22<00:00, 68.1MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Checking if NVIDIA GPU is available\n",
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "W_model = whisper.load_model(\"medium\", device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F81WeS25R7fC",
        "outputId": "adb68442-e361-49e6-9a90-20d6773e6297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jpM-ZP0h6OXDyuAfN1V6U7fvkdZuLLpU\n",
            "To: /content/Samples/Sample1.mp3\n",
            "100%|██████████| 7.69M/7.69M [00:00<00:00, 25.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uwpA8Wuix2QJ0gvvnZk7CtaSsoC21iEj\n",
            "To: /content/Samples/Sample2.mp3\n",
            "100%|██████████| 8.13M/8.13M [00:00<00:00, 25.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iLKcK5Z9IaYrKzaPQLMIZm3vJ7DssCAz\n",
            "To: /content/Samples/Sample3.mp3\n",
            "100%|██████████| 10.1M/10.1M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "#File Project1_Data.json\n",
        "file_id = [\"1jpM-ZP0h6OXDyuAfN1V6U7fvkdZuLLpU\",\n",
        "           \"1uwpA8Wuix2QJ0gvvnZk7CtaSsoC21iEj\",\n",
        "           \"1iLKcK5Z9IaYrKzaPQLMIZm3vJ7DssCAz\"\n",
        "]\n",
        "import os\n",
        "os.makedirs('Samples')\n",
        "datafilename =[ \"./Samples/Sample1.mp3\",\n",
        "        \"./Samples/Sample2.mp3\",\n",
        "        \"./Samples/Sample3.mp3\"]\n",
        "for i in range(len(file_id)):\n",
        "   with open(datafilename[i], 'wb') as f:\n",
        "     gdown.download(f\"https://drive.google.com/uc?id={file_id[i]}\", datafilename[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6F6riawW2JRw",
        "outputId": "8f39c858-2377-4270-bc5b-10d339ebdb69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "messages_system= {\"role\": \"system\",\n",
        "                        \"content\": '''You are a simulated IELTS Speaking examiner and i am a candidate of this exam. Your primary task is to conduct a mock IELTS Speaking test, adhering closely to the IELTS standards.\n",
        "# The IELTS standards are as follows:\n",
        "    Part 1: Introduction and Interview (4-5 minutes)\n",
        "    - Introduce yourself and confirm the candidate's identity.\n",
        "    - Ask questions about familiar topics such as home, family, work, studies, and interests.\n",
        "    - Example questions:\n",
        "      - Can you tell me about your hometown?\n",
        "      - What do you enjoy doing in your free time?\n",
        "      - Can you describe your job or what you are studying?\n",
        "\n",
        "    Part 2: Long Turn (3-4 minutes)\n",
        "    - Provide a task card with a topic and points to cover.\n",
        "    - Give the candidate 1 minute to prepare and make notes if they wish.\n",
        "    - Ask the candidate to speak for 1-2 minutes on the topic.\n",
        "    - Example task card:\n",
        "      - Describe a memorable trip you have taken.\n",
        "        - Where you went?\n",
        "        - Why you went there?\n",
        "        - What you did there?\n",
        "        - Explain why this trip was memorable for you?\n",
        "    - After the candidate's long turn, ask one or two follow-up questions related to the topic.\n",
        "\n",
        "    Part 3: Discussion (4-5 minutes)\n",
        "    - Engage in a discussion based on the topic from Part 2.\n",
        "    - Ask more abstract and complex questions to allow the candidate to express opinions and ideas.\n",
        "    - Example questions:\n",
        "      - How do you think travel experiences can change a person's view of the world?\n",
        "      - What are the benefits and drawbacks of traveling to different countries?\n",
        "      - How has tourism impacted the environment in popular travel destinations?\n",
        "# Process\n",
        "1. Ask the candidate if they want to:\n",
        "    a. Simulate a mock IELTS Speaking test\n",
        "    b. Analyze a transcript of an existing recorded IELTS Speaking test\n",
        "\n",
        "2. Based on the candidate's choice:\n",
        "    a. If they choose to simulate a mock IELTS Speaking test:\n",
        "        - Conduct the test following the IELTS standards.\n",
        "        - Structure the test into three parts of the IELTS standards.\n",
        "        - Comply with the following regulations:\n",
        "          - Display randomly topics for Part 1, and a single topic for Part 2 and 3, see more topics to choose from at page https://www.ielts-mentor.com/speaking.\n",
        "          - Do not the reuse  example questions provided in the IELTS standards above.\n",
        "          - please remember that you must ask the candidate question one by one it means that you must offer another question after the student give you response text which including prouncation scores, do not give questions one time because I do not want to respond it by one time\n",
        "          - Focus on asking questions and responding appropriately without changing the candidate's words.\n",
        "          - Maintain a strict adherence to the IELTS Speaking test format, avoiding off-topic conversations. If the user's input deviates, gently guide them back to the test format.\n",
        "    b. If they choose to analyze a transcript of an IELTS Speaking test:\n",
        "        - Classify the dialogue into examiner and test taker parts adhering closely to the IELTS standards .\n",
        "        - Summarize the dialogue in your response.\n",
        "        - Provide constructive feedback and next steps.\n",
        "\n",
        "3. After the candidate answers the final question:\n",
        "    - Provide constructive feedback based on their performance, highlighting strengths and areas for improvement.\n",
        "    - Provide a strict estimate of specific overall band scores and sub-scores (e.g., if the sub-score is 6.0-6.5, your estimation should be 6.0) for fluency and coherence, lexical resource, grammatical range and accuracy, and pronunciation.\n",
        "    - Include a disclaimer that this evaluation is generated by ChatGPT and is for reference only; official IELTS exam results may vary.\n",
        "    then, ask the candidate if they want to a full, improved, and detailed answer based on the discussed topics and questions?\n",
        "4. if the candidate do not want, end the discusion.\n",
        "  If they want to a full, improved, and detailed answer based on the discussed topics and questions:\n",
        "    - you make a full, improved, and detailed answer based on the discussed topics and questions in each part that used in this IELTS Speaking test.\n",
        "    - Present questions and answers like:\n",
        "          'Part number': Topic\n",
        "            Question: Content Question\n",
        "            Answer: Content your Answer\n",
        "            ...\n",
        "5. ask the candidate if they ant to a summary of the main challenges you faced during the simulation along with some key vocabulary and phrases to learn?\n",
        "if they want:\n",
        "    - summarize the main challenges, mistake the candidate faced during the simulation along.\n",
        "    - then give some usefull vocabulary and phrases that came up during the test to learn.\n",
        "'''\n",
        "}\n",
        "'''\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLMjBhPzBTF7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "-aMUTzWsOuDG",
        "outputId": "5ea0fea7-52a7-4ead-c212-5e14366b76e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2a7d569fa1df27ad89.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2a7d569fa1df27ad89.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set your OpenAI API key\n",
        "client = OpenAI(api_key = \"sk-oGx8ZhLZ0xMahXqAF3tGcsTQhfO7WGIiRC0UlwtNYKJU9pxu\",\n",
        "                base_url=\"https://api.chatanywhere.tech/v1\")\n",
        "#mess = \"\"\n",
        "#with open('prompt.txt', 'r') as file:\n",
        " ##   mess = file.read()\n",
        "#messages_system= {\"role\": \"system\",\n",
        "                 #      \"content\": mess\n",
        "                   #    }\n",
        "\n",
        "# Transcribe audio using OpenAI's Whisper\n",
        "def transcribe_audio(audio):\n",
        "    segment_length = 600000\n",
        "    # Open the audio file\n",
        "    audio_file = AudioSegment.from_file(audio)\n",
        "    # Get the duration of the audio file in milliseconds\n",
        "    duration_ms = len(audio_file)\n",
        "    # Calculate the number of segments needed\n",
        "    num_segments = math.ceil(duration_ms / segment_length)\n",
        "    # Create an empty string to hold the concatenated text\n",
        "    all_text = \"\"\n",
        "    # Split the audio file into segments\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_length\n",
        "        end = min((i + 1) * segment_length, duration_ms)\n",
        "        segment = audio_file[start:end]\n",
        "        segment.export(f\"segment_{i}.mp3\", format=\"mp3\")\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        audio_file = open(f\"segment_{i}.mp3\", \"rb\")\n",
        "        transcript = W_model.transcribe(f\"segment_{i}.mp3\")\n",
        "        all_text += transcript['text']\n",
        "    return all_text\n",
        "import csv\n",
        "def respond(\n",
        "    message,\n",
        "    history: list[tuple[str, str]],\n",
        "    mic=None,\n",
        "    text = \"Simulator IELTS Speaking test\",\n",
        "):\n",
        "    global messages_system\n",
        "    messages = [messages_system]\n",
        "    audio = None\n",
        "    if len(history) != 0:\n",
        "      history_chat = []\n",
        "      with open('chat_transcript.csv', 'r') as f:\n",
        "        history_chat = csv.reader(f)\n",
        "        for val in history_chat:\n",
        "          if val[0]:\n",
        "              messages.append({\"role\": val[0], \"content\": val[1]})\n",
        "\n",
        "    if mic is not None:\n",
        "          audio = mic\n",
        "    elif  len(message[\"files\"])!= 0:\n",
        "          audio = message[\"files\"][0]\n",
        "          #return message[\"files\"][0]\n",
        "    #else:\n",
        "          #return \"You must either provide a mic recording or a file\"\n",
        "    transcript = \"\"\n",
        "    if audio is not None:\n",
        "        transcript = transcribe_audio(audio)\n",
        "    transcript += \"\\n\" + message[\"text\"]\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": transcript})\n",
        "\n",
        "    response = \"\"\n",
        "    response = client.chat.completions.create(\n",
        "          messages= messages,\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "      )\n",
        "    systems_message = response.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": systems_message})\n",
        "    chat_transcript =[]\n",
        "    for message in messages:\n",
        "        if message['role'] != 'system':\n",
        "            chat_transcript.append([message['role'] , message['content']])\n",
        "    with open('chat_transcript.csv', 'w') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(chat_transcript)\n",
        "    yield systems_message\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "demo = gr.ChatInterface(\n",
        "    respond,\n",
        "    additional_inputs=[\n",
        "        gr.Audio(sources=\"microphone\", type=\"numpy\", label=\"Speak here...\"),\n",
        "    ],\n",
        "    title=\"AI Auditor\",\n",
        "    description='''AI Alliance for Audio Analytics Team. Our project's objective is to conduct a mock IELTS Speaking test, adhering closely to the IELTS standards.\n",
        "    upload a file record of your test or start a  ock IELTS Speaking test''',\n",
        "    textbox = gr.MultimodalTextbox(interactive=True, file_types=[\"audio\"], placeholder=\"upload file record...\"),\n",
        "\n",
        "    multimodal=True,\n",
        ")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpx0mTSfBJuC"
      },
      "source": [
        "Demo by gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBJcmbmItWqw"
      },
      "outputs": [],
      "source": [
        "# Set your OpenAI API key\n",
        "client = OpenAI(api_key = \"sk-oGx8ZhLZ0xMahXqAF3tGcsTQhfO7WGIiRC0UlwtNYKJU9pxu\",\n",
        "                base_url=\"https://api.chatanywhere.tech/v1\")\n",
        "\n",
        "\n",
        "# Transcribe audio using OpenAI's Whisper\n",
        "def transcribe_audio(audio):\n",
        "    segment_length = 600000\n",
        "    # Open the audio file\n",
        "    audio_file = AudioSegment.from_file(audio)\n",
        "    # Get the duration of the audio file in milliseconds\n",
        "    duration_ms = len(audio_file)\n",
        "    # Calculate the number of segments needed\n",
        "    num_segments = math.ceil(duration_ms / segment_length)\n",
        "    # Create an empty string to hold the concatenated text\n",
        "    all_text = \"\"\n",
        "    # Split the audio file into segments\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_length\n",
        "        end = min((i + 1) * segment_length, duration_ms)\n",
        "        segment = audio_file[start:end]\n",
        "        segment.export(f\"segment_{i}.mp3\", format=\"mp3\")\n",
        "\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        audio_file = open(f\"segment_{i}.mp3\", \"rb\")\n",
        "        transcript = W_model.transcribe(f\"segment_{i}.mp3\")\n",
        "        all_text += transcript['text']\n",
        "\n",
        "    return all_text\n",
        "\n",
        "# Analyze transcript using OpenAI's GPT-3\n",
        "def analyze_transcript(transcript):\n",
        "    global messages_system\n",
        "    messages=[]\n",
        "    messages.append(messages_system)\n",
        "    messages.append({\"role\": \"user\", \"content\": transcript})\n",
        "    response = client.chat.completions.create(\n",
        "          messages= messages,\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "      )\n",
        "\n",
        "    systems_message = response.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": systems_message})\n",
        "\n",
        "    chat_transcript = \"\"\n",
        "    for message in messages:\n",
        "        if message['role'] != 'system':\n",
        "            chat_transcript += message['role'] + \": \" + message['content'] + \"\\n\\n\"\n",
        "    result = \"Transcript: \" + transcript + \"\\n\\n\"\n",
        "    return systems_message #+\"\\n\\n\"+ result\n",
        "# Define the transcription and analysis function\n",
        "def transcribe_and_analyze(mic=None, file=None):\n",
        "    if mic is not None:\n",
        "        audio = mic\n",
        "    elif file is not None:\n",
        "        audio = file\n",
        "    else:\n",
        "        return \"You must either provide a mic recording or a file\"\n",
        "    # Transcribe the audio to text\n",
        "    transcript = transcribe_audio(audio)\n",
        "    # Analyze sentiment and summarize\n",
        "    analysis = analyze_transcript(transcript)\n",
        "    return analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXwSF6rDsAG1"
      },
      "outputs": [],
      "source": [
        "\n",
        "io = gr.Interface(fn=transcribe_and_analyze,\n",
        "                      inputs=[\n",
        "                          gr.Audio(sources=\"microphone\", type=\"numpy\", label=\"Speak here...\"),\n",
        "                          gr.Audio(sources=\"upload\", type = \"filepath\"),\n",
        "                      ],\n",
        "                      outputs=\"text\",\n",
        "                      title=\"AI Auditor for\",\n",
        "                      description='''AI Alliance for Audio Analytics Team. Our project's objective is to conduct a mock IELTS Speaking test, adhering closely to the IELTS standards\n",
        "                      ''',\n",
        "                      examples=[[None, \"./Samples/Sample1.mp3\"],\n",
        "                                [None, \"./Samples/Sample2.mp3\"],\n",
        "                                [None, \"./Samples/Sample3.mp3\"]],\n",
        "                      )\n",
        "\n",
        "io.launch(share=True, debug = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}